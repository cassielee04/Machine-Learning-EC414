{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EC 414 - Spring 2019**\n",
    "\n",
    "**HW 4 - QDA/LDA & Logistic Regression 1**\n",
    "\n",
    "Due:  Wednesday Feb 27 (In class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Obtaining QDA & LDA Decision Rules: **\n",
    "\n",
    "In this problem, we will consider Quadratic and Linear Discriminant Analysis for $m$ classes where $y \\in \\{1,...,m \\}$ represents a class index. In class, we looked at the simple 2-class LDA. Using the MPE (Most Probable Explanation) rule: \n",
    "\n",
    "$h_{MPE} (\\boldsymbol{x})= \\text{argmax}_{y} p(y|\\boldsymbol{x},\\theta)$, \n",
    "\n",
    "obtain the QDA & LDA decision rules: \n",
    "\n",
    "$h_{QDA} (\\boldsymbol{x}) = \\text{argmin}_y [\\frac{1}{2} (\\boldsymbol{x}-\\boldsymbol{\\mu}_y)^T \\Sigma_y^{-1} (\\boldsymbol{x}-\\boldsymbol{\\mu}_y) + \\frac{1}{2} \\text{log} (\\text{det}(\\Sigma_y)) - \\text{log} (p(y))]$,\n",
    "\n",
    "$h_{LDA} (\\boldsymbol{x}) = \\text{argmax}_y [(\\boldsymbol{\\mu}_y^T \\Sigma^{-1} ) \\cdot \\boldsymbol{x} - \\frac{1}{2} \\boldsymbol{\\mu}_y^T \\Sigma^{-1} \\boldsymbol{\\mu}_y + \\text{log}(p(y))]$.\n",
    "\n",
    "Please show all intermediate steps in your analysis. As a tip, it may be expedient to use Bayes Rule in your analysis along with the fact that, for QDA:\n",
    "\n",
    "$p(\\boldsymbol{x}|y,\\theta) = N(\\boldsymbol{\\mu}_y,\\Sigma_y)(\\boldsymbol{x}) = \\frac{1}{((2 \\pi)^d \\text{ det}(\\Sigma_y))^{1/2}} e^{\\frac{1}{2} (\\boldsymbol{x}-\\boldsymbol{\\mu}_y)^T \\Sigma_y^{-1} (\\boldsymbol{x}-\\boldsymbol{\\mu}_y)}$, \n",
    "\n",
    "and for LDA:\n",
    "\n",
    "$ \\Sigma_y = \\Sigma \\text{ } \\forall \\text{ } y \\in \\{1,...,m \\}$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Implementation of LDA**\n",
    "\n",
    "In this problem, we will explore the implementation and application of LDA on an artificial dataset. Using any built in Python command/function for LDA in this problem is prohibited.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Generate $3$ $2$D Gaussian clusters of data with the following means and covariances:\n",
    "\n",
    "$\\boldsymbol{\\mu}_1 = [2,2]^T, \\boldsymbol{\\mu}_2 = [-7,-7]^T, \\boldsymbol{\\mu}_3 = [-8,-1]^T$,\n",
    "\n",
    "$\\Sigma = [[0.5,0];[0,0.5]]$.\n",
    "\n",
    "Let each cluster of data have $500$ points. Plot the generated Gaussian data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write code here:\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "Mean1 = np.array([2,2])\n",
    "Mean1 = Mean1.T\n",
    "\n",
    "Mean2 = np.array([-7,-7])\n",
    "Mean2 = Mean2.T\n",
    "\n",
    "Mean3 = np.array([-8,-1])\n",
    "Mean3 = Mean3.T\n",
    "\n",
    "cov = np.array([[0.5,0],[0,0.5]])\n",
    "\n",
    "ones = np.ones(500)\n",
    "\n",
    "label1 = np.ones(500).reshape(500,1)\n",
    "label2 = (ones+1).reshape(500,1)\n",
    "label3 = (ones+2).reshape(500,1)\n",
    "\n",
    "\n",
    "x1_samples = np.random.multivariate_normal(Mean1,cov,500)\n",
    "x1_samples = np.column_stack((x1_samples, label1))\n",
    "\n",
    "x2_samples = np.random.multivariate_normal(Mean2,cov,500)\n",
    "x2_samples = np.column_stack((x2_samples, label2))\n",
    "\n",
    "x3_samples = np.random.multivariate_normal(Mean3,cov,500)\n",
    "x3_samples = np.column_stack((x3_samples, label3))\n",
    "\n",
    "\n",
    "\n",
    "plt.scatter(x1_samples[:,0],x1_samples[:,1], marker='+')\n",
    "plt.scatter(x2_samples[:,0],x2_samples[:,1], c= 'green', marker='o')\n",
    "plt.scatter(x3_samples[:,0],x3_samples[:,1], marker='*')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Randomly split all the data and labels into training and testing sets using an $85\\%$/$15\\%$  train/test split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1275, 2)\n",
      "(1275,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "newdata = []\n",
    "\n",
    "newdatax = np.concatenate((x1_samples[:,0],x2_samples[:,0],x3_samples[:,0]),axis=0)\n",
    "newdatay = np.concatenate((x1_samples[:,1],x2_samples[:,1],x3_samples[:,1]),axis=0)\n",
    "labels = np.concatenate((x1_samples[:,2],x2_samples[:,2],x3_samples[:,2]),axis=0)\n",
    "\n",
    "newy = np.stack((newdatay,labels)).T\n",
    "\n",
    "# newdata = newdata.T\n",
    "\n",
    "# print(newdata.shape)\n",
    "\n",
    "x_train, x_test, y_train, ytest = train_test_split(newdatax,newy,test_size = 0.15)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(x_train.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Obtain the necessary parameter values for ($\\widehat{\\boldsymbol{\\mu}}_y \\text{ } \\forall \\text{ } y$,$\\widehat{\\Sigma}$,$\\widehat{p}(y)$) used for obtaining the LDA decision rule derived in Q$1$.  As a reminder, the preceding values can be obtained as:\n",
    "\n",
    "$\\widehat{p}(y) = \\frac{n_y}{n}$,\n",
    "\n",
    "$\\widehat{\\boldsymbol{\\mu}}_y = \\frac{1}{n_y} \\sum_{i \\in \\{ 1,...,n\\}: y = y_j} \\boldsymbol{x}_i$,\n",
    "\n",
    "$\\widehat{\\Sigma} = \\frac{1}{n} \\sum_{i=1}^n (\\boldsymbol{x}_i-\\widehat{\\boldsymbol{\\mu}}_{y_i})(\\boldsymbol{x}_i-\\widehat{\\boldsymbol{\\mu}}_{y_i})^T$,\n",
    "\n",
    "where $n$ is the number of training data points and $n_y$ is the number of occurrences of class $y$ in the training set. \n",
    "\n",
    "Please display the resulting values of the preceding variables using print statements.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p values:\n",
      "  [0.3333333333333333, 0.3247058823529412, 0.3419607843137255]\n",
      "Empirical means:\n",
      " [[ 2.03415796  2.06110526]\n",
      " [-7.00418094 -7.02327798]\n",
      " [-8.00652367 -0.98978006]]\n",
      "covariance:\n",
      " [[0.45094118 0.0012973 ]\n",
      " [0.0012973  0.48524357]]\n"
     ]
    }
   ],
   "source": [
    "# Write code here:\n",
    "\n",
    "Ymean =[]\n",
    "p = []\n",
    "Xsum1 = 0\n",
    "Ysum1 = 0\n",
    "Xsum2 = 0\n",
    "Ysum2 = 0\n",
    "Xsum3 = 0\n",
    "Ysum3 = 0\n",
    "var1x= np.zeros(1275)\n",
    "var1y = np.zeros(1275)\n",
    "var1xy = np.zeros(1275)\n",
    "covs = np.zeros([2,2])\n",
    "var2=[]\n",
    "var3=[]\n",
    "sum1 = []\n",
    "sum2 = []\n",
    "sum3 = []\n",
    "tot_mean = np.zeros([3,2])\n",
    "counter1 = 0\n",
    "counter2 = 0\n",
    "counter3 = 0\n",
    "######for class 1###############\n",
    "\n",
    "\n",
    "for i in range (0,y_train.shape[0]):\n",
    "    if(y_train[i][1] == 1):\n",
    "        counter1+=1\n",
    "        Xsum1 += x_train[i]\n",
    "        Ysum1 += y_train[i][0]        \n",
    "\n",
    "Xmean1 = Xsum1/counter1\n",
    "Ymean1 = Ysum1/counter1\n",
    "Ymean.append(Ymean1)\n",
    "\n",
    "for i in range (0,y_train.shape[0]):\n",
    "    if(y_train[i][1] == 1):\n",
    "        var1x[i]= x_train[i]-Xmean1\n",
    "        var1y[i] = y_train[i][0]-Ymean1\n",
    "    \n",
    "        \n",
    "newvar1x = var1x @ var1x.T\n",
    "newvar1y = var1y@var1y.T\n",
    "covxy=np.mean(var1x*var1y)\n",
    "cov1x = newvar1x/counter1\n",
    "cov1y = newvar1y/counter1\n",
    "\n",
    "\n",
    "covs[0][0] =cov1x\n",
    "covs[0][1]=covxy\n",
    "covs[1][0]=covxy\n",
    "covs[1][1]=cov1y\n",
    "\n",
    "sum1.append(Xmean1)\n",
    "sum1.append(Ymean1)\n",
    "\n",
    "\n",
    "p1 = counter1/1275\n",
    "\n",
    "#####for class 2################\n",
    "\n",
    "for i in range (0,y_train.shape[0]):\n",
    "    if(y_train[i][1] == 2):\n",
    "        counter2+=1\n",
    "        Xsum2 += x_train[i]\n",
    "        Ysum2 += y_train[i][0]  \n",
    "\n",
    "p2 = counter2/1275\n",
    "\n",
    "Xmean2 = Xsum2/counter2\n",
    "Ymean2 = Ysum2/counter2\n",
    "\n",
    "Ymean.append(Ymean2)\n",
    "\n",
    "sum2.append(Xmean2)\n",
    "sum2.append(Ymean2)\n",
    "\n",
    "\n",
    "#####for class 3################\n",
    "\n",
    "for i in range(0,y_train.shape[0]):\n",
    "    if(y_train[i][1] == 3):\n",
    "        counter3 += 1\n",
    "        Xsum3 += x_train[i]\n",
    "        Ysum3 += y_train[i][0]  \n",
    "p3 = counter3/1275\n",
    "\n",
    "Xmean3 = Xsum3/counter3\n",
    "Ymean3 = Ysum3/counter3\n",
    "\n",
    "Ymean.append(Ymean3)\n",
    "\n",
    "sum3.append(Xmean3)\n",
    "sum3.append(Ymean3)\n",
    "\n",
    "\n",
    "p.append(p1)\n",
    "p.append(p2)\n",
    "p.append(p3)\n",
    "\n",
    "tot_mean[0,0]=sum1[0]\n",
    "tot_mean[0,1]= sum1[1]\n",
    "tot_mean[1,0] = sum2[0]\n",
    "tot_mean[1,1] = sum2[1]\n",
    "tot_mean[2,0] = sum3[0]\n",
    "tot_mean[2,1] = sum3[1]\n",
    "# tot_mean.append(sum2)\n",
    "# tot_mean.append(sum3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"p values:\\n \",p)\n",
    "print(\"Empirical means:\\n\",tot_mean )\n",
    "print(\"covariance:\\n\",covs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# d) Since we know ($\\widehat{\\boldsymbol{\\mu}}_y \\text{ } \\forall \\text{ } y$,$\\widehat{\\Sigma}$,$\\widehat{p}(y)$), we can in turn obtain the LDA decision rule. Let:\n",
    "\n",
    "$\\boldsymbol{\\beta}_y = \\Sigma^{-1} \\boldsymbol{\\mu}_y $,\n",
    "\n",
    "$\\alpha_y = - \\frac{1}{2} \\boldsymbol{\\mu}_y^T \\Sigma^{-1} \\boldsymbol{\\mu}_y + \\text{log}(p(y))$;\n",
    "\n",
    "with this, the LDA decision rule can be re-expressed as:\n",
    "\n",
    "$h_{LDA} (\\boldsymbol{x}) = \\text{argmax}_y \\text{ } \\boldsymbol{\\beta}_y^T \\boldsymbol{x} + \\alpha_y$.  \n",
    "\n",
    "The objective function in the preceding equation basically projects $\\boldsymbol{x}$ into $1$ dimension and offsets it.  \n",
    "\n",
    "Obtain and display the values of $\\boldsymbol{\\beta}_y \\forall y$ and $\\alpha_y \\forall y$ using print statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta:\n",
      " [[  4.06831591   4.12221051]\n",
      " [-14.00836189 -14.04655596]\n",
      " [-16.01304735  -1.97956013]]\n",
      "alpha:\n",
      " [[ -9.48456575]\n",
      " [-99.50981975]\n",
      " [-66.15714513]]\n"
     ]
    }
   ],
   "source": [
    "# Write code here:\n",
    "\n",
    "cov_inv = np.linalg.inv(cov)\n",
    "Beta = cov_inv@tot_mean.T\n",
    "print(\"Beta:\\n\",Beta.T)\n",
    "\n",
    "alpha_val = -0.5*tot_mean@cov_inv@tot_mean.T + np.log(p)\n",
    "#print(alpha_val)\n",
    "\n",
    "#extract diagonal\n",
    "alpha = np.zeros([3,1])\n",
    "\n",
    "alpha[0][0] = alpha_val[0][0]\n",
    "alpha[1][0] = alpha_val[1][1]\n",
    "alpha[2][0] = alpha_val[2][2]\n",
    "\n",
    "print(\"alpha:\\n\",alpha)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Using the derived LDA decision rule, obtain and display the Correct Classification Rates (CCR) for the training and testing sets. Also, explain the resulting CCRs.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA - Train CCR:  1.0\n",
      "LDA - Test CCR:  1.0\n"
     ]
    }
   ],
   "source": [
    " # Write code here:\n",
    "point_x = np.zeros([1275,2])\n",
    "\n",
    "for i in range(0,1275):\n",
    "    point_x[i,0] = x_train[i]\n",
    "    point_x[i,1] = y_train[i,0]\n",
    "\n",
    "# print(point_x.shape)\n",
    "    \n",
    "h = Beta.T @ point_x.T + alpha\n",
    "h_argmax = h.argmax(axis = 0)+1\n",
    "\n",
    "# print(h.shape)\n",
    "\n",
    "counter = 0\n",
    "for i in range(0,1275):\n",
    "    if h_argmax[i] == y_train[i,1]:\n",
    "        counter += 1\n",
    "print(\"LDA - Train CCR: \",counter/1275)\n",
    "\n",
    "\n",
    "\n",
    "point_test = np.zeros([225,2])\n",
    "for i in range(0,225):\n",
    "    point_test[i,0] = x_test[i]\n",
    "    point_test[i,1] = ytest[i,0]\n",
    "\n",
    "h_test = Beta.T @ point_test.T + alpha\n",
    "h_argmax_test = h_test.argmax(axis = 0)+1\n",
    "\n",
    "\n",
    "counter_ = 0\n",
    "for i in range(0,225):\n",
    "    if h_argmax_test[i] == ytest[i,1]:\n",
    "        counter_ += 1\n",
    "print(\"LDA - Test CCR: \",counter_/225)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Explain CCR:\n",
    "According to the CCR obtained, both train and test CCR has values of 1.0. This is obvious because we implemented our \n",
    "points and lables from the training set. Then, we apply to hLDA function (which has alpha and beta derived from\n",
    "                                                                         training set). \n",
    "Because for the CCR the training data value for labels are compared to hLDA, so that the number of getting\n",
    "all correct labels should be the same as number of dataset. \n",
    "\n",
    "Also the mean values for each classes are far and the spreads are small that gives CCR even close to 1, since \n",
    "ther is less chance to be overlab between two clusters.                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Here, we will test our LDA classifier on $5$ new data points:\n",
    "    \n",
    "$\\boldsymbol{x}_1 = [10,10]^T,\\boldsymbol{x}_2 = [-10,10]^T,\\boldsymbol{x}_3 = [-10,-10]^T,\\boldsymbol{x}_4 = [10,-10]^T,\\boldsymbol{x}_5 = [0,0]^T$\n",
    "\n",
    "Plot these new test points along with the original Gaussian data on a new figure. For each new test point, compute the score of the test point belonging to class $y \\text{ } \\forall \\text{ } y \\in \\{1,...,m \\}$ as:  $\\text{score}_y = \\boldsymbol{\\beta}_y^T \\boldsymbol{x} + \\alpha_y$ and display the scores using print statements.  \n",
    "\n",
    "Describe the resulting scores and rationalize why they make sense based on proximity of a new test point to a certain data cluster.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 10.  10.]\n",
      " [-10.  10.]\n",
      " [-10. -10.]\n",
      " [ 10. -10.]\n",
      " [  0.   0.]]\n",
      "[[  72.42069847 -380.05899821 -246.08321988]\n",
      " [  -8.94561975  -99.89176051   74.17772707]\n",
      " [ -91.38982997  181.03935871  113.76892963]\n",
      " [ -10.02351176  -99.12787899 -206.49201732]\n",
      " [  -9.48456575  -99.50981975  -66.15714513]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write code here:\n",
    "\n",
    "\n",
    "x_all = np.zeros([5,2])\n",
    "x_all[0][0] = 10\n",
    "x_all[0][1] = 10\n",
    "x_all[1][0] = -10\n",
    "x_all[1][1] = 10\n",
    "x_all[2][0] = -10\n",
    "x_all[2][1] = -10\n",
    "x_all[3][0] = 10\n",
    "x_all[3][1] = -10\n",
    "x_all[4][0] = 0\n",
    "x_all[4][1] = 0\n",
    "\n",
    "\n",
    "print(x_all)\n",
    "\n",
    "\n",
    "scorey = Beta.T@x_all.T+alpha\n",
    "scorey = scorey.T\n",
    "print(scorey)\n",
    "\n",
    "plt.scatter(x_all[0][0],x_all[0][1])\n",
    "plt.scatter(x_all[1][0],x_all[1][1])\n",
    "plt.scatter(x_all[2][0],x_all[2][1])\n",
    "plt.scatter(x_all[3][0],x_all[3][1])\n",
    "plt.scatter(x_all[4][0],x_all[4][1])\n",
    "\n",
    "\n",
    "\n",
    "x1_samples = np.random.multivariate_normal(Mean1,cov,500)\n",
    "x1_samples = np.column_stack((x1_samples, label1))\n",
    "\n",
    "x2_samples = np.random.multivariate_normal(Mean2,cov,500)\n",
    "x2_samples = np.column_stack((x2_samples, label2))\n",
    "\n",
    "x3_samples = np.random.multivariate_normal(Mean3,cov,500)\n",
    "x3_samples = np.column_stack((x3_samples, label3))\n",
    "\n",
    "\n",
    "\n",
    "plt.scatter(x1_samples[:,0],x1_samples[:,1], marker='+')\n",
    "plt.scatter(x2_samples[:,0],x2_samples[:,1], c= 'green', marker='o')\n",
    "plt.scatter(x3_samples[:,0],x3_samples[:,1], marker='*')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "If we look at the new points added to the plots, these new points are corresponds to the different \n",
    "clusters/classes.\n",
    "For example, the point (10,10) has the highest score value because it corresponds to the brown cluster(class1)\n",
    "the most among three different classes.\n",
    "Thus, the value that corresponds to [10,10] has the biggest scale. On the other hand, we can see that (0,0)\n",
    "has the largest scale at the 5th row. The reason is because it is close to class1 and far from the other 2 classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Logistic Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, we will implement Logistic Regression using the built in capability (from sklearn).\n",
    "\n",
    "Form a Logistic Regression classifer using the training data from Q$2$ and apply it to the training and testing sets from Q$2$. Obtain the CCRs for the training and testing sets; also, explain the resulting CCRs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1275, 2)\n",
      "CCR for Train data is: 1.0\n",
      "CCR for Test data is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "train_labels = np.zeros([1275,1])\n",
    "test_labels = np.zeros([225,1])\n",
    "\n",
    "for i in range(0,1275):\n",
    "    train_labels[i] = y_train[i,1]\n",
    "    \n",
    "for i in range(0,225):\n",
    "    test_labels[i] = ytest[i,1]\n",
    "    \n",
    "logreg = LogisticRegression()\n",
    "#logreg.fit(point_x,train_labels)\n",
    "X = np.stack((x_train,y_train[:,0]), axis=1)\n",
    "print(X.shape)\n",
    "logreg.fit(X,y_train[:,1])    \n",
    "predict_train_label = logreg.predict(X)\n",
    " \n",
    "\n",
    "    \n",
    "count_train=0\n",
    "\n",
    "for i in range(0,1275):\n",
    "    if(train_labels[i] == predict_train_label[i]):\n",
    "        count_train += 1\n",
    "\n",
    "print(\"CCR for Train data is:\",count_train/1275 )\n",
    "    \n",
    "\n",
    "    \n",
    "X_test = np.stack((x_test,ytest[:,0]), axis=1)\n",
    "\n",
    "logreg.fit(X_test,ytest[:,1])    \n",
    "predict_test_label = logreg.predict(X_test)\n",
    " \n",
    "\n",
    "count_test=0\n",
    "\n",
    "for i in range(0,225):\n",
    "    if(test_labels[i] == predict_test_label[i]):\n",
    "        count_test += 1\n",
    "\n",
    "print(\"CCR for Test data is:\",count_test/225 )\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# logreg.fit(X, Y)\n",
    "\n",
    "# Write code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "By observing the training and test sets for LDA the CCR results 1. The only difference of Logistic Regression\n",
    "and LDA is the mathmatical difference. Therefore, the CCR for Logistic Regression should not be big different \n",
    "from LDA.According to the plot, the cluster variance are very small and also the class means are far from \n",
    "each other. Therefore, regarding these factors the Logistic Regression should be close to 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
